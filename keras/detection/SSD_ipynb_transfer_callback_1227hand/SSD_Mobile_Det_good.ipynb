{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 20:00:58.390741: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-28 20:00:58.778371: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-28 20:00:58.780874: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-28 20:00:59.932644: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, Dense, DepthwiseConv2D,add\n",
    "from keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "import math\n",
    "import keras\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "from keras import layers as KL\n",
    "from Anchors import get_anchors\n",
    "from Datasets import SSDDatasets\n",
    "from learning_rate import WarmUpCosineDecayScheduler\n",
    "from loss import MultiboxLoss\n",
    "from Models import SSD300\n",
    "from utils import get_classes, show_config\n",
    "from log_record import record_log, read_log\n",
    "from keras.callbacks import (EarlyStopping, LearningRateScheduler,\n",
    "                             ModelCheckpoint, TensorBoard)\n",
    "from callbacks import (ExponentDecayScheduler, LossHistory,\n",
    "                       ParallelModelCheckpoint, EvalCallback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['hand'] num_classes: 2\n",
      "type: <class 'numpy.ndarray'> shape: (1242, 4)\n",
      "Train on 1440 samples, val on 178 samples, with batch size 32.\n",
      "Configurations:\n",
      "----------------------------------------------------------------------\n",
      "|                     keys |                                   values|\n",
      "----------------------------------------------------------------------\n",
      "|             classes_path |             ./model_data/voc_classes.txt|\n",
      "|               model_path |                                         |\n",
      "|              input_shape |                               [120, 160]|\n",
      "|                    Epoch |                                      500|\n",
      "|               batch_size |                                       32|\n",
      "|                       lr |                                    0.001|\n",
      "|           optimizer_type |                                     Adam|\n",
      "|                 momentum |                                    0.937|\n",
      "|                num_train |                                     1440|\n",
      "|                  num_val |                                      178|\n",
      "----------------------------------------------------------------------\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 20:06:08.816896: W tensorflow/c/c_api.cc:304] Operation '{name:'Conv2D_conf_DD3_2/bias/Assign' id:1278 op device:{requested: '', assigned: ''} def:{{{node Conv2D_conf_DD3_2/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](Conv2D_conf_DD3_2/bias, Conv2D_conf_DD3_2/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/tmp/ipykernel_29918/787098737.py:102: UserWarning: `model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n",
      "2024-02-28 20:06:09.054444: W tensorflow/c/c_api.cc:304] Operation '{name:'beta_2/Assign' id:1911 op device:{requested: '', assigned: ''} def:{{{node beta_2/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](beta_2, beta_2/Initializer/initial_value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 设置训练参数\n",
    "    Epoch = 500  # 训练100 epochs\n",
    "    lr = 1e-3  # Adam优化器，所以较小的学习率\n",
    "    optimizer_type = \"Adam\"\n",
    "    momentum = 0.937\n",
    "    batch_size = 32\n",
    "    imgcolor = 'grey'  # imgcolor选“rgb” or “grey”, 则处理图像变单通道或者三通道\n",
    "    tmp_dir = str(datetime.datetime.strftime(datetime.datetime.now(), '%Y%m%d'))\n",
    "    save_dir = \"/home/zhangyouan/桌面/zya/NN_net/network/SSD/IMX_681_ssd_mobilenet_git/keras/detection/SSD_ipynb_transfer_callback_1227hand/output/20240228\"\n",
    "        \n",
    "    # 设置SSD参数\n",
    "    cls_name_path = \"./model_data/voc_classes.txt\"  # 导入目标检测类别；\n",
    "    input_shape = [120, 160]  # 输入的尺寸大小\n",
    "    anchor_size = [32, 59, 86, 113, 141, 168]  # 用于设定先验框的大小，根据公式计算而来；如果要检测小物体，修改浅层先验框的大小，越小的话，识别的物体越小；    \n",
    "    train_annotation_path = r'/home/zhangyouan/桌面/zya/dataset/681/hand/2007_train.txt'  # 训练图片路径和标签\n",
    "    val_annotation_path = r'/home/zhangyouan/桌面/zya/dataset/681/hand/2007_test.txt'  # 验证图片路径和标签\n",
    "        \n",
    "    # 1. 获取classes和anchor\n",
    "    class_names, num_cls = get_classes(cls_name_path)\n",
    "    num_cls += 1  # 增加一个背景类别\n",
    "    print(\"class_names:\", class_names, \"num_classes:\", num_cls)\n",
    "    \n",
    "    # 2. 获取anchors, 输出的是归一化之后的anchors\n",
    "    anchor = get_anchors(input_shape, anchor_size)\n",
    "    print(\"type:\",type(anchor), \"shape:\", np.shape(anchor))\n",
    "\n",
    "    # 3. 模型编译\n",
    "    K.clear_session()\n",
    "    model_path = \"\"\n",
    "    # model_path = \"./output/20230804_3/good_detection_test_callback.h5\"\n",
    "    model = SSD300((input_shape[0], input_shape[1], 1), num_cls)\n",
    "    # model.save(\"template.h5\")\n",
    "    # model.summary()\n",
    "    if model_path != \"\":\n",
    "        model.load_weights(model_path, by_name = True, skip_mismatch=True)\n",
    "       \n",
    "    # 4. 优化器\n",
    "    # optimizer = Adam(lr = lr, beta_1=momentum)\n",
    "    # optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    from tensorflow.keras.optimizers import legacy\n",
    "    optimizer = legacy.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    # 5. 导入数据集\n",
    "    with open(train_annotation_path, encoding='utf-8') as f:\n",
    "        train_lines = f.readlines()\n",
    "    with open(val_annotation_path, encoding='utf-8') as f:\n",
    "        val_lines = f.readlines()\n",
    "    num_train = len(train_lines)\n",
    "    num_val = len(val_lines)\n",
    "    epoch_step = num_train // batch_size\n",
    "    epoch_step_val = num_val // batch_size\n",
    "    train_dataloader = SSDDatasets(train_lines, input_shape, anchor, batch_size, num_cls, train=False, imgcolor=imgcolor)\n",
    "    val_dataloader = SSDDatasets(val_lines, input_shape, anchor, batch_size, num_cls, train=False, imgcolor=imgcolor)\n",
    "    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "    \n",
    "    # 6. 编译模型\n",
    "    # losses = {'mbox_loc_final':MultiboxLoss(num_cls, neg_pos_ratio=3.0).compute_loc_loss,\n",
    "            #   'cls_conf_final':MultiboxLoss(num_cls, neg_pos_ratio=3.0).compute_conf_loss}\n",
    "    # losses2 = [MultiboxLoss(num_cls, neg_pos_ratio=3.0).compute_loc_loss,MultiboxLoss(num_cls, neg_pos_ratio=3.0).compute_conf_loss]\n",
    "    model.compile(optimizer=optimizer, loss = MultiboxLoss(num_cls, neg_pos_ratio=3.0).compute_loss)\n",
    "    \n",
    "    # 7. 设计learning rate;\n",
    "    total_steps = int(Epoch * num_train / batch_size)\n",
    "    # 7.1 compute the number of warmup batches.\n",
    "    warmup_epochs = 10\n",
    "    warmup_steps = int(warmup_epochs * num_train / batch_size)\n",
    "    # 7.2 create the learning rate scheduler\n",
    "    warm_up_lr = WarmUpCosineDecayScheduler(learning_rate_base=lr,\n",
    "                                            total_steps=total_steps,\n",
    "                                            warmup_learning_rate=4e-06,\n",
    "                                            warmup_steps=warmup_steps,\n",
    "                                            hold_base_rate_steps=20)\n",
    "    time_str = datetime.datetime.strftime(datetime.datetime.now(), '%Y_%m_%d_%H_%M_%S')\n",
    "    log_dir = os.path.join(save_dir, \"loss_\" + str(time_str))\n",
    "    \n",
    "    # # 8. 精度评价: pending --> 还没构建；\n",
    "    eval_flag = True\n",
    "    eval_period = 10\n",
    "    eval_callback = EvalCallback(model, input_shape, anchor, class_names, num_cls, val_lines, log_dir, eval_flag=eval_flag, period = eval_period)\n",
    "    show_config(\n",
    "        classes_path=cls_name_path, model_path=model_path, input_shape=input_shape, \\\n",
    "        Epoch=Epoch, batch_size=batch_size, \\\n",
    "        lr=lr, optimizer_type=optimizer_type, momentum=momentum, \\\n",
    "        num_train=num_train, num_val=num_val\n",
    "    )\n",
    "    \n",
    "    callbacks_list = [\n",
    "        #早停回调，\n",
    "        # keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4),\n",
    "        warm_up_lr, # 学习率的调整\n",
    "        # 学习率调整方法2. \n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=0, mode='auto',min_lr=0.000001),\n",
    "        # Epoch结束回调LearningRateSchrduler(schrduler, verbose=1),\n",
    "        keras.callbacks.TensorBoard(log_dir=os.path.join(save_dir, 'unetlogs'), update_freq=1000), #参数分别为日志存储路径和每多少step进行一次记录，此处不应取太小，会拖慢训练过程\n",
    "        eval_callback,  # 精度评价；\n",
    "    ]\n",
    "    # 8. 开始训练；\n",
    "    history = model.fit_generator(\n",
    "        generator=train_dataloader,\n",
    "        steps_per_epoch=epoch_step,\n",
    "        validation_data=val_dataloader,\n",
    "        validation_steps=epoch_step_val,\n",
    "        epochs=Epoch,\n",
    "        # callbacks = [warm_up_lr]\n",
    "        callbacks = callbacks_list   \n",
    "    )  # 使用tensorboard --logdir=\"\" 调用查看loss\n",
    "    \n",
    "    record_log(history, filename = os.path.join(save_dir, \"unetlogs/log.txt\"))\n",
    "    model.save(os.path.join(save_dir, \"hand_detection_20240228.h5\"))\n",
    "    model.save(os.path.join(save_dir, \"hand_detection_20240228.pb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no accuracy, only loss.\n"
     ]
    }
   ],
   "source": [
    "from log_record import record_log, read_log\n",
    "from utils import visual_train\n",
    "\n",
    "history = read_log(\"/home/zhangyouan/桌面/zya/NN_net/network/SSD/IMX_681_ssd_mobilenet_git/keras/detection/SSD_ipynb_transfer_callback/output/20230819/unetlogs/log.txt\")\n",
    "visual_train(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no accuracy, only loss.\n"
     ]
    }
   ],
   "source": [
    "from log_record import record_log, read_log\n",
    "from utils import visual_train\n",
    "\n",
    "history = read_log(\"/home/zhangyouan/桌面/zya/NN_net/network/SSD/IMX_681_ssd_mobilenet_git/keras/detection/SSD_ipynb_transfer_callback_0919_cola/output/20231205/unetlogs/log.txt\")\n",
    "visual_train(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('stc': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6a050d9f10360465fbc02ae273ccd06cb1948ad5cd96cc14a3b3a9694a266bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
