{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['PcScreen', 'PhoneScreen', 'book']\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.3350 Acc: 0.9055\n",
      "val Loss: 0.1706 Acc: 0.9667\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.1085 Acc: 0.9787\n",
      "val Loss: 0.0780 Acc: 0.9833\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.0648 Acc: 0.9888\n",
      "val Loss: 0.0501 Acc: 0.9900\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.0476 Acc: 0.9924\n",
      "val Loss: 0.0391 Acc: 0.9933\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.0356 Acc: 0.9955\n",
      "val Loss: 0.0495 Acc: 0.9850\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.0286 Acc: 0.9968\n",
      "val Loss: 0.0297 Acc: 0.9950\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.0217 Acc: 0.9987\n",
      "val Loss: 0.0293 Acc: 0.9933\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.0210 Acc: 0.9980\n",
      "val Loss: 0.0246 Acc: 0.9967\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.0177 Acc: 0.9989\n",
      "val Loss: 0.0315 Acc: 0.9917\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.0172 Acc: 0.9986\n",
      "val Loss: 0.0239 Acc: 0.9967\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.0166 Acc: 0.9991\n",
      "val Loss: 0.0267 Acc: 0.9933\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0168 Acc: 0.9991\n",
      "val Loss: 0.0254 Acc: 0.9933\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0172 Acc: 0.9982\n",
      "val Loss: 0.0232 Acc: 0.9983\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0204 Acc: 0.9977\n",
      "val Loss: 0.0241 Acc: 0.9967\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0158 Acc: 0.9991\n",
      "val Loss: 0.0259 Acc: 0.9950\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0153 Acc: 0.9987\n",
      "val Loss: 0.0235 Acc: 0.9950\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0165 Acc: 0.9987\n",
      "val Loss: 0.0224 Acc: 0.9967\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0160 Acc: 0.9986\n",
      "val Loss: 0.0252 Acc: 0.9950\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0149 Acc: 0.9993\n",
      "val Loss: 0.0229 Acc: 0.9967\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0162 Acc: 0.9977\n",
      "val Loss: 0.0264 Acc: 0.9933\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0154 Acc: 0.9993\n",
      "val Loss: 0.0273 Acc: 0.9917\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0145 Acc: 0.9993\n",
      "val Loss: 0.0224 Acc: 0.9983\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0145 Acc: 0.9996\n",
      "val Loss: 0.0222 Acc: 0.9983\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0161 Acc: 0.9982\n",
      "val Loss: 0.0241 Acc: 0.9983\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.0172 Acc: 0.9986\n",
      "val Loss: 0.0272 Acc: 0.9933\n",
      "\n",
      "Training complete in 84m 59s\n",
      "Best val Acc: 0.9983\n",
      "模型已保存到 'model.pth'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "# 定义图像转换步骤\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((120, 160)),  # 调整大小为 160x120\n",
    "        transforms.Grayscale(num_output_channels=1),  # 转换为灰度图，输出通道数为1\n",
    "        transforms.ToTensor(),  # 转换为 PyTorch 张量\n",
    "        transforms.Normalize([0.5], [0.5])  # 对灰度图进行标准化，均值和标准差为0.5\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((120, 160)),  # 调整大小为 160x120\n",
    "        transforms.Grayscale(num_output_channels=1),  # 转换为灰度图，输出通道数为1\n",
    "        transforms.ToTensor(),  # 转换为 PyTorch 张量\n",
    "        transforms.Normalize([0.5], [0.5])  # 对灰度图进行标准化，均值和标准差为0.5\n",
    "    ])\n",
    "}\n",
    "\n",
    "# 数据集目录\n",
    "data_dir = r\"/home/zhangyouan/桌面/zya/dataset/681/PCScreen_Book_PhoneScreen\"\n",
    "\n",
    "# 加载数据集\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# 设备配置 (GPU or CPU)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MV2Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor=2, stride=1):\n",
    "        super(MV2Block, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.use_residual = self.stride == 1 and in_channels == out_channels\n",
    "\n",
    "        expanded_channels = in_channels * expansion_factor\n",
    "        self.expand_conv = nn.Conv2d(in_channels, expanded_channels, kernel_size=1, bias=False)\n",
    "        self.expand_bn = nn.BatchNorm2d(expanded_channels)\n",
    "\n",
    "        self.depthwise_conv = nn.Conv2d(expanded_channels, expanded_channels, kernel_size=3, stride=stride, padding=1, groups=expanded_channels, bias=False)\n",
    "        self.depthwise_bn = nn.BatchNorm2d(expanded_channels)\n",
    "\n",
    "        self.project_conv = nn.Conv2d(expanded_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.project_bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu6(self.expand_bn(self.expand_conv(x)))\n",
    "        out = F.relu6(self.depthwise_bn(self.depthwise_conv(out)))\n",
    "        out = self.project_bn(self.project_conv(out))\n",
    "        if self.use_residual:\n",
    "            out = x + out\n",
    "        return out\n",
    "\n",
    "class MobileNetV2Style(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MobileNetV2Style, self).__init__()\n",
    "        # 输入层\n",
    "        self.input_conv = nn.Conv2d(1, 3, kernel_size=3, padding=1)  # 单通道输入 (灰度图)\n",
    "        self.input_bn = nn.BatchNorm2d(3)\n",
    "        \n",
    "        # MobileNetV2 架构\n",
    "        self.mv2_block1 = MV2Block(3, 16, stride=1)\n",
    "        self.mv2_block2 = MV2Block(16, 32, stride=2)\n",
    "        self.mv2_block3 = MV2Block(32, 32, stride=1)\n",
    "        self.mv2_block4 = MV2Block(32, 32, stride=2)\n",
    "        self.mv2_block5 = MV2Block(32, 16, stride=1)\n",
    "        self.mv2_block6 = MV2Block(16, 16, stride=1)\n",
    "        \n",
    "        # 池化层和全连接层\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(16 * 15 * 20, 64)  # 输入尺寸根据池化后的大小调整\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(64, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_bn(self.input_conv(x)))\n",
    "        \n",
    "        x = self.mv2_block1(x)\n",
    "        x = self.mv2_block2(x)\n",
    "        x = self.mv2_block3(x)\n",
    "        x = self.mv2_block4(x)\n",
    "        x = self.mv2_block5(x)\n",
    "        x = self.mv2_block6(x)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 创建模型实例并将其移到设备\n",
    "model = MobileNetV2Style().to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # 每个 epoch 都有一个训练和验证阶段\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # 训练模式\n",
    "            else:\n",
    "                model.eval()   # 验证模式\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # 遍历数据\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # 梯度清零\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 前向传播\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # 仅在训练阶段反向传播和优化\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # 统计损失和正确的预测数\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # 深度复制模型\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    # 加载最佳模型权重\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=25)\n",
    "\n",
    "# 保存模型的状态字典\n",
    "torch.save(model.state_dict(), 'model_test_batch32.pth')\n",
    "print(\"模型已保存到 'model.pth'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
