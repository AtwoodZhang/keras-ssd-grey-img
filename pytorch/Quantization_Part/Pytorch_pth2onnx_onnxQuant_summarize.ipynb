{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment:\n",
    "beautifulsoup4 \n",
    "bleach \n",
    "dm-tree==0.1.8\n",
    "flatbuffers==23.5.26\n",
    "google-auth==2.22.0\n",
    "google-auth-oauthlib==1.0.0\n",
    "google-pasta==0.2.0\n",
    "h5py==3.9.0\n",
    "ipykernel \n",
    "ipython \n",
    "jupyter\n",
    "keras==2.13.1\n",
    "Markdown==3.4.1\n",
    "matplotlib==3.5.3\n",
    "notebook\n",
    "numpy \n",
    "onnx==1.14.0\n",
    "onnx-simplifier==0.4.33\n",
    "onnxoptimizer==0.3.13\n",
    "onnxruntime==1.15.1\n",
    "opencv-python==4.6.0.66\n",
    "opt-einsum==3.3.0\n",
    "packaging \n",
    "pandas==1.4.3\n",
    "Pillow==9.4.0\n",
    "platformdirs \n",
    "protobuf==4.23.4\n",
    "psutil \n",
    "ptyprocess \n",
    "pycocotools==2.0.4\n",
    "requests \n",
    "scikit-learn==1.1.2\n",
    "scipy==1.9.1\n",
    "sklearn==0.0\n",
    "tensorboard==2.13.0\n",
    "tensorboard-data-server==0.7.1\n",
    "tensorboard-plugin-wit==1.8.1\n",
    "tensorflow==2.13.0\n",
    "tensorflow-estimator==2.13.0\n",
    "tensorflow-io-gcs-filesystem==0.33.0\n",
    "termcolor==2.3.0\n",
    "torch==1.12.1\n",
    "torchaudio==0.12.1\n",
    "torchvision==0.13.1\n",
    "tornado \n",
    "tqdm==4.64.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置参数\n",
    "batch_size = 128\n",
    "learning_rate = 1e-2\n",
    "num_epoches = 30\n",
    "\n",
    "\n",
    "# 设置数据集\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# 定义模型\n",
    "class Cnn(nn.Module):\n",
    "    def __init__(self, in_dim, n_class):\n",
    "        super(Cnn, self).__init__()    # super用法:Cnn继承父类nn.Model的属性，并用父类的方法初始化这些属性\n",
    "        self.conv = nn.Sequential(     #padding=2保证输入输出尺寸相同(参数依次是:输入深度，输出深度，ksize，步长，填充)\n",
    "            nn.Conv2d(in_dim, 6, 5, stride=1, padding=2),  # (28*28*1)\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(6, 16, 5, stride=1, padding=0),\n",
    "            nn.ReLU(True), \n",
    "            nn.Conv2d(16, 16, 5, stride=1, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 6, 5, stride=1, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1536, 120), \n",
    "            nn.Linear(120, 84), \n",
    "            nn.Linear(84, n_class))\n",
    "\n",
    "    def forward(self, x):  # x.size=([128, 1, 28, 28])\n",
    "        out = self.conv(x)  # out.size=([128, 6, 16, 16])\n",
    "        out = torch.flatten(out, start_dim=1, end_dim=3)  # out.size = ([128, 1536])\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "**********\n",
      "Finish 1 epoch, Train Loss: 2.299097, Acc: 0.123550, Test Loss: 2.283773, Acc: 0.128200 \n",
      "\n",
      "epoch 2\n",
      "**********\n",
      "Finish 2 epoch, Train Loss: 1.006178, Acc: 0.661183, Test Loss: 0.307233, Acc: 0.911000 \n",
      "\n",
      "epoch 3\n",
      "**********\n",
      "Finish 3 epoch, Train Loss: 0.277282, Acc: 0.918467, Test Loss: 0.208130, Acc: 0.940700 \n",
      "\n",
      "epoch 4\n",
      "**********\n",
      "Finish 4 epoch, Train Loss: 0.190588, Acc: 0.944383, Test Loss: 0.145093, Acc: 0.955200 \n",
      "\n",
      "epoch 5\n",
      "**********\n",
      "Finish 5 epoch, Train Loss: 0.143336, Acc: 0.957783, Test Loss: 0.126834, Acc: 0.961000 \n",
      "\n",
      "epoch 6\n",
      "**********\n",
      "Finish 6 epoch, Train Loss: 0.118813, Acc: 0.964850, Test Loss: 0.117879, Acc: 0.964300 \n",
      "\n",
      "epoch 7\n",
      "**********\n",
      "Finish 7 epoch, Train Loss: 0.105171, Acc: 0.968783, Test Loss: 0.096067, Acc: 0.972100 \n",
      "\n",
      "epoch 8\n",
      "**********\n",
      "Finish 8 epoch, Train Loss: 0.095082, Acc: 0.971817, Test Loss: 0.086646, Acc: 0.974600 \n",
      "\n",
      "epoch 9\n",
      "**********\n",
      "Finish 9 epoch, Train Loss: 0.087431, Acc: 0.974017, Test Loss: 0.087894, Acc: 0.972600 \n",
      "\n",
      "epoch 10\n",
      "**********\n",
      "Finish 10 epoch, Train Loss: 0.081682, Acc: 0.975900, Test Loss: 0.076726, Acc: 0.975900 \n",
      "\n",
      "epoch 11\n",
      "**********\n",
      "Finish 11 epoch, Train Loss: 0.076210, Acc: 0.977233, Test Loss: 0.078792, Acc: 0.976200 \n",
      "\n",
      "epoch 12\n",
      "**********\n",
      "Finish 12 epoch, Train Loss: 0.071990, Acc: 0.978733, Test Loss: 0.068046, Acc: 0.978600 \n",
      "\n",
      "epoch 13\n",
      "**********\n",
      "Finish 13 epoch, Train Loss: 0.068484, Acc: 0.979950, Test Loss: 0.068402, Acc: 0.979300 \n",
      "\n",
      "epoch 14\n",
      "**********\n",
      "Finish 14 epoch, Train Loss: 0.065511, Acc: 0.980433, Test Loss: 0.069338, Acc: 0.978700 \n",
      "\n",
      "epoch 15\n",
      "**********\n",
      "Finish 15 epoch, Train Loss: 0.063225, Acc: 0.981050, Test Loss: 0.063891, Acc: 0.980600 \n",
      "\n",
      "epoch 16\n",
      "**********\n",
      "Finish 16 epoch, Train Loss: 0.060116, Acc: 0.981717, Test Loss: 0.068221, Acc: 0.978700 \n",
      "\n",
      "epoch 17\n",
      "**********\n",
      "Finish 17 epoch, Train Loss: 0.058170, Acc: 0.982400, Test Loss: 0.066349, Acc: 0.979600 \n",
      "\n",
      "epoch 18\n",
      "**********\n",
      "Finish 18 epoch, Train Loss: 0.055471, Acc: 0.983433, Test Loss: 0.062674, Acc: 0.980900 \n",
      "\n",
      "epoch 19\n",
      "**********\n",
      "Finish 19 epoch, Train Loss: 0.053355, Acc: 0.983850, Test Loss: 0.058743, Acc: 0.981900 \n",
      "\n",
      "epoch 20\n",
      "**********\n",
      "Finish 20 epoch, Train Loss: 0.051941, Acc: 0.984583, Test Loss: 0.058066, Acc: 0.981700 \n",
      "\n",
      "epoch 21\n",
      "**********\n",
      "Finish 21 epoch, Train Loss: 0.050290, Acc: 0.984950, Test Loss: 0.060912, Acc: 0.981100 \n",
      "\n",
      "epoch 22\n",
      "**********\n",
      "Finish 22 epoch, Train Loss: 0.048749, Acc: 0.984967, Test Loss: 0.058564, Acc: 0.981800 \n",
      "\n",
      "epoch 23\n",
      "**********\n",
      "Finish 23 epoch, Train Loss: 0.047303, Acc: 0.985833, Test Loss: 0.061987, Acc: 0.981200 \n",
      "\n",
      "epoch 24\n",
      "**********\n",
      "Finish 24 epoch, Train Loss: 0.045688, Acc: 0.986183, Test Loss: 0.059918, Acc: 0.982400 \n",
      "\n",
      "epoch 25\n",
      "**********\n",
      "Finish 25 epoch, Train Loss: 0.044865, Acc: 0.986183, Test Loss: 0.058336, Acc: 0.981500 \n",
      "\n",
      "epoch 26\n",
      "**********\n",
      "Finish 26 epoch, Train Loss: 0.043103, Acc: 0.987233, Test Loss: 0.057295, Acc: 0.981600 \n",
      "\n",
      "epoch 27\n",
      "**********\n",
      "Finish 27 epoch, Train Loss: 0.042616, Acc: 0.986883, Test Loss: 0.059308, Acc: 0.982200 \n",
      "\n",
      "epoch 28\n",
      "**********\n",
      "Finish 28 epoch, Train Loss: 0.041326, Acc: 0.987467, Test Loss: 0.054309, Acc: 0.983300 \n",
      "\n",
      "epoch 29\n",
      "**********\n",
      "Finish 29 epoch, Train Loss: 0.039305, Acc: 0.987867, Test Loss: 0.062740, Acc: 0.982900 \n",
      "\n",
      "epoch 30\n",
      "**********\n",
      "Finish 30 epoch, Train Loss: 0.039482, Acc: 0.988033, Test Loss: 0.058594, Acc: 0.982100 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "model = Cnn(1, 10)  # 图片大小是28x28,输入深度是1，最终输出的10类\n",
    "use_gpu = torch.cuda.is_available()  # 判断是否有GPU加速\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "# 定义loss和optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 开始训练\n",
    "for epoch in range(num_epoches):\n",
    "    print('epoch {}'.format(epoch + 1))      # .format为输出格式，formet括号里的即为左边花括号的输出\n",
    "    print('*' * 10)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        img, label = data\n",
    "        if use_gpu:\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        running_loss += loss.item() * label.size(0)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        num_correct = (pred == label).sum()\n",
    "        accuracy = (pred == label).float().mean()\n",
    "        running_acc += num_correct.item()\n",
    "        # 向后传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            img, label = data\n",
    "            if use_gpu:\n",
    "                img = Variable(img).cuda()\n",
    "                label = Variable(label).cuda()\n",
    "            else:\n",
    "                img = Variable(img)\n",
    "                label = Variable(label)\n",
    "            out = model(img)\n",
    "            loss = criterion(out, label)\n",
    "            eval_loss += loss.item() * label.size(0)\n",
    "            _, pred = torch.max(out, 1)\n",
    "            num_correct = (pred == label).sum()\n",
    "            eval_acc += num_correct.item()\n",
    "    print('Finish {} epoch, Train Loss: {:.6f}, Acc: {:.6f}, Test Loss: {:.6f}, Acc: {:.6f} '.format(\n",
    "        epoch + 1, \n",
    "        running_loss / (len(train_dataset)), \n",
    "        running_acc / (len(train_dataset)), \n",
    "        eval_loss / (len(test_dataset)), \n",
    "        eval_acc / (len(test_dataset))))\n",
    "    print()\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), './Pytorch_pth2onnx_onnxQuant_summarize1010.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pth模型导出onnx模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(1, 1, 28, 28, strides=[784, 784, 28, 1], requires_grad=0, device=cpu),\n",
      "      %conv.0.weight : Float(6, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=1, device=cpu),\n",
      "      %conv.0.bias : Float(6, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv.2.weight : Float(16, 6, 5, 5, strides=[150, 25, 5, 1], requires_grad=1, device=cpu),\n",
      "      %conv.2.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv.4.weight : Float(16, 16, 5, 5, strides=[400, 25, 5, 1], requires_grad=1, device=cpu),\n",
      "      %conv.4.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv.6.weight : Float(6, 16, 5, 5, strides=[400, 25, 5, 1], requires_grad=1, device=cpu),\n",
      "      %conv.6.bias : Float(6, strides=[1], requires_grad=1, device=cpu),\n",
      "      %fc.0.weight : Float(120, 1536, strides=[1536, 1], requires_grad=1, device=cpu),\n",
      "      %fc.0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),\n",
      "      %fc.1.weight : Float(84, 120, strides=[120, 1], requires_grad=1, device=cpu),\n",
      "      %fc.1.bias : Float(84, strides=[1], requires_grad=1, device=cpu),\n",
      "      %fc.2.weight : Float(10, 84, strides=[84, 1], requires_grad=1, device=cpu),\n",
      "      %fc.2.bias : Float(10, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %input.1 : Float(1, 6, 28, 28, strides=[4704, 784, 28, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1], onnx_name=\"Conv_0\"](%input, %conv.0.weight, %conv.0.bias) # /home/zya/.conda/envs/IMX500/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Conv_16 : Float(1, 6, 28, 28, strides=[4704, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"Relu_1\"](%input.1) # /home/zya/.conda/envs/IMX500/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %input.4 : Float(1, 16, 24, 24, strides=[9216, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_2\"](%onnx::Conv_16, %conv.2.weight, %conv.2.bias) # /home/zya/.conda/envs/IMX500/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Conv_18 : Float(1, 16, 24, 24, strides=[9216, 576, 24, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"Relu_3\"](%input.4) # /home/zya/.conda/envs/IMX500/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %input.8 : Float(1, 16, 20, 20, strides=[6400, 400, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_4\"](%onnx::Conv_18, %conv.4.weight, %conv.4.bias) # /home/zya/.conda/envs/IMX500/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Conv_20 : Float(1, 16, 20, 20, strides=[6400, 400, 20, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"Relu_5\"](%input.8) # /home/zya/.conda/envs/IMX500/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %input.12 : Float(1, 6, 16, 16, strides=[1536, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_6\"](%onnx::Conv_20, %conv.6.weight, %conv.6.bias) # /home/zya/.conda/envs/IMX500/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0\n",
      "  %onnx::Flatten_22 : Float(1, 6, 16, 16, strides=[1536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"Relu_7\"](%input.12) # /home/zya/.conda/envs/IMX500/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %onnx::Gemm_23 : Float(1, 1536, strides=[1536, 1], requires_grad=1, device=cpu) = onnx::Flatten[axis=1, onnx_name=\"Flatten_8\"](%onnx::Flatten_22) # /tmp/ipykernel_31011/613243325.py:39:0\n",
      "  %onnx::Gemm_24 : Float(1, 120, strides=[120, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"Gemm_9\"](%onnx::Gemm_23, %fc.0.weight, %fc.0.bias) # /home/zya/.conda/envs/IMX500/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %onnx::Gemm_25 : Float(1, 84, strides=[84, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"Gemm_10\"](%onnx::Gemm_24, %fc.1.weight, %fc.1.bias) # /home/zya/.conda/envs/IMX500/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %output : Float(1, 10, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"Gemm_11\"](%onnx::Gemm_25, %fc.2.weight, %fc.2.bias) # /home/zya/.conda/envs/IMX500/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  return (%output)\n",
      "\n",
      "Exporting .pth model to onnx model has been successful!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "import os\n",
    "\n",
    "def pth_to_onnx(input, checkpoint, onnx_path, input_names=['input'], output_names=['output']):\n",
    "    if not onnx_path.endswith('.onnx'):\n",
    "        print('Warning! The onnx model name is not correct, \\ please give a name that ends with \\'.onnx\\'!')\n",
    "        return 0\n",
    "\n",
    "    model = Cnn(1, 10)  # 导入模型\n",
    "    model.load_state_dict(torch.load(checkpoint))  # 初始化权重\n",
    "    model.eval()\n",
    "    \n",
    "    # opset_version=15  # 设置opset的版本号\n",
    "    torch.onnx.export(model, input, onnx_path, verbose=True, input_names=input_names, output_names=output_names, opset_version=15) #指定模型的输入，以及onnx的输出路径\n",
    "    print(\"Exporting .pth model to onnx model has been successful!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    checkpoint = './Pytorch_pth2onnx_onnxQuant_summarize1010.pth'\n",
    "    onnx_path = './Pytorch_pth2onnx_onnxQuant_summarize1010_op15.onnx'\n",
    "    input = torch.randn(1, 1, 28, 28)\n",
    "    pth_to_onnx(input, checkpoint, onnx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. onnx模型量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 Convolution Network 模型\n",
    "class Cnn(nn.Module):\n",
    "    def __init__(self, in_dim, n_class):\n",
    "        super(Cnn, self).__init__()    # super用法:Cnn继承父类nn.Model的属性，并用父类的方法初始化这些属性\n",
    "        self.quant = torch.quantization.QuantStub()  # 静态量化时量化桩用于量化数据\n",
    "        self.conv = nn.Sequential(     #padding=2保证输入输出尺寸相同(参数依次是:输入深度，输出深度，ksize，步长，填充)\n",
    "            nn.Conv2d(in_dim, 6, 5, stride=1, padding=2),  # (28*28*1)\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(6, 16, 5, stride=1, padding=0),\n",
    "            nn.ReLU(True), \n",
    "            nn.Conv2d(16, 16, 5, stride=1, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 6, 5, stride=1, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            )\n",
    "        self.fc = nn.Sequential(nn.Linear(1536, 120), nn.Linear(120, 84), nn.Linear(84, n_class))\n",
    "        self.dequant = torch.quantization.DeQuantStub() # 取消量化桩\n",
    "\n",
    "    def forward(self, x):  # x.size=([128, 1, 28, 28])\n",
    "        x = self.quant(x)  # 量化数据，从fp32->uint8\n",
    "        out = self.conv(x)  # out.size=([128, 6, 16, 16])\n",
    "        out = torch.flatten(out, start_dim=1, end_dim=3)  # out.size = ([128, 1536])\n",
    "        out = self.fc(out)\n",
    "        x = self.dequant(out)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n"
     ]
    }
   ],
   "source": [
    "# create a model instance\n",
    "model_fp32 = Cnn(1, 10)  # 创建模型\n",
    "checkpoint = './Pytorch_pth2onnx_onnxQuant_summarize1010.pth'\n",
    "model_fp32.load_state_dict(torch.load(checkpoint))  # 初始化权重\n",
    "model_fp32.eval()  # 推理模式\n",
    "model_fp32.qconfig = torch.quantization.get_default_qconfig('fbjemm')  # 设置量化配置\n",
    "model_fp32_fused= model_fp32 # torch.quantization.fuse_modules(model_fp32, [['conv', 'relu']])\n",
    "model_fp32_prepared = torch.quantization.prepare(model_fp32_fused)\n",
    "input_fp32 = torch.randn(1, 1, 28, 28)  # 产生伪数据用于测试模型；\n",
    "model_fp32_prepared(input_fp32) # 数据量化操作，准备范围，刻度等；\n",
    "model_int8 = torch.quantization.convert(model_fp32_prepared)  # 量化数据\n",
    "\n",
    "torch.onnx.export(\n",
    "    model_int8,             # model being run\n",
    "    input_fp32,                         # model input (or a tuple for multiple inputs)\n",
    "    './Pytorch_pth2onnx_pthQuant_summarize1010_op16.onnx',   # where to save the model (can be a file or file-like object)\n",
    "    export_params=True,        # store the trained parameter weights inside the model file\n",
    "    opset_version=16,          # the ONNX version to export the model to\n",
    "    input_names = ['input'],   # the model's input names\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX simplifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. https://convertmodel.com/ online converter and simplifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. through onnx simplifier: pip install onnx-simplifier\n",
    "(https://blog.csdn.net/Mrrunsen/article/details/122870507?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-1-122870507-blog-128111258.235^v38^pc_relevant_default_base&spm=1001.2101.3001.4242.2&utm_relevant_index=4)\n",
    "then through python -m onnxsim input_onnx_model output_onnx_model to simplier the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(IMX500) zya@SSSLXSRVLS002:~/zya/AI/NNet/classification/MNIST_recog$ python -m  onnxsim /home/zya/zya/AI/NNet/classification/MNIST_recog/Pytorch_pth2onnx_pthQuant_summarize1010_op15.onnx /home/zya/zya/AI/NNet/classification/MNIST_recog/Pytorch_pth2onnx_pthQuant_summarize1010_op15_sim.onnx\n",
    "Your model contains \"Tile\" ops or/and \"ConstantOfShape\" ops. Folding these ops can make the simplified model much larger. If it is not expected, please specify \"--no-large-tensor\" (which will lose \n",
    "some optimization chances)\n",
    "Simplifying...\n",
    "Finish! Here is the difference:\n",
    "┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
    "┃                  ┃ Original Model ┃ Simplified Model ┃\n",
    "┡━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
    "│ Cast             │ 20             │ 0                │\n",
    "│ Constant         │ 45             │ 45               │\n",
    "│ ConstantOfShape  │ 7              │ 0                │\n",
    "│ Conv             │ 4              │ 4                │\n",
    "│ DequantizeLinear │ 27             │ 27               │\n",
    "│ Flatten          │ 1              │ 1                │\n",
    "│ Gemm             │ 3              │ 3                │\n",
    "│ Identity         │ 39             │ 0                │\n",
    "│ QuantizeLinear   │ 13             │ 13               │\n",
    "│ Relu             │ 4              │ 4                │\n",
    "│ Model Size       │ 216.5KiB       │ 213.0KiB         │\n",
    "└──────────────────┴────────────────┴──────────────────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或者写jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/hjxu2016/article/details/127265957?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-1-127265957-blog-122870507.235^v38^pc_relevant_default_base&spm=1001.2101.3001.4242.2&utm_relevant_index=4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('IMX500')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6898330a772008c0efb32b6e51c3fb8f855e3228c7dbee5aae70bc6dd7211e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
