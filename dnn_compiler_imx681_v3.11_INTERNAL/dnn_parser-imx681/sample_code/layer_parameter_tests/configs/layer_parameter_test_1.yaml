name: layer_parameter_test_1
data:
  datapath: "./data/imagenet" 
testing:
  model_file: "./models/quantized_models"
  test_image: "./data/test/test_all_127.pgm"
  num_classes: 10
  input_w: 160
  input_h: 120
  debug_folder: "./debug"
training:
  use_cuda: True
  devices: 0
  epochs: 50
  lr: 0.001
  momentum: 0.9 
  batch_size: 4
  classes: 10
  save_trained_root_path: "./models/trained_models/" 
  save_quantized_root_path: "./models/quantized_models/"
model:
  quantize: True
  input_width: 160
  input_height: 120
  input_channels: 1
  layer_00:
    set: True
    name: "layer_00"
    type: "DW" # Depthwise
    in_channels: 1
    out_channels: 4
    K: 4
    kernel: 3
    stride: 2
    padding: 
      type: "same"
      padding_w: 1
      padding_h: 1
    BN: True
    activation: "" 
  layer_01:
    set: False
    name: "layer_01"
    type: "" 
    activation: "" 
  layer_02:
    set: True
    name: "layer_02"
    type: "Conv" # Depthwise
    in_channels: 16
    out_channels: 8
    K: 1
    kernel: 3
    stride: 2
    padding:
      type: "same"
      padding_w: 1
      padding_h: 1
    BN: True
    activation: "RELU6" 
  layer_03:
    set: True
    name: "layer_03"
    type: "Interpolate" # UpSampling or Down Sampling
    in_channels: 8
    out_channels: 8
    BN: True
    activation: "" 
    kernel: 0
    stride: 0
    padding:
      type: "same"
      padding_w: 1
      padding_h: 1
  layer_04:
    set: True
    name: "layer_04"
    type: "Conv" # Normal Conv2d
    in_channels: 8
    out_channels: 8
    kernel: 3
    stride: 2
    padding:
      type: "same"
      padding_w: 1
      padding_h: 1
    BN: True
    activation: "RELU6" 
  layer_05:
    set: True
    name: "layer_05"
    type: "Conv" # Normal Conv2d
    in_channels: 8
    out_channels: 16
    kernel: 3
    stride: 2
    padding:
      type: "same"
      padding_w: 1
      padding_h: 1
    BN: True
    activation: "RELU6" 
  layer_06:
    set: True
    name: "layer_06"
    type: "Interpolate" # UpSampling or Down Sampling
    in_channels: 16
    out_channels: 16
    BN: True
    activation: "" 
    kernel: 0
    stride: 0
    padding:
      type: "same"
      padding_w: 1
      padding_h: 1
  layer_07:
    set: True
    name: "layer_07"
    type: "Conv" # Normal Conv2d
    in_channels: 16
    out_channels: 10
    kernel: 3
    stride: 2
    padding:
      type: "same"
      padding_w: 1
      padding_h: 1
    BN: True
    activation: "" 
  layer_08:
    set: False
    name: "layer_08"
    type: "" 
    activation: "" 
  layer_09:
    set: True
    name: "layer_09"
    type: "Interpolate" # UpSampling or Down Sampling
    in_channels: 10
    out_channels: 10
    BN: True
    activation: "" 
    kernel: 0
    stride: 0
    padding:
      type: "same"
      padding_w: 1
      padding_h: 1
  layer_10:
    set: True
    name: "layer_10"
    type: "Conv" # Normal Conv2d
    in_channels: 10
    out_channels: 15
    kernel: 3
    stride: 2
    padding:
      type: "same"
      padding_w: 1
      padding_h: 1
    BN: True
    activation: "" 
  layer_11:
    set: False
    name: "layer_11"
    type: "" 
    activation: "" 
  layer_12:
    set: True
    name: "layer_12"
    type: "Conv" # Normal Conv2d
    in_channels: 48
    out_channels: 20
    kernel: 3
    stride: 2
    padding:
      type: "same"
      padding_w: 1
      padding_h: 1
    BN: True
    activation: "" 
  layer_13:
    set: True
    name: "layer_13"
    type: "Interpolate" # UpSampling or Down Sampling
    in_channels: 20
    out_channels: 20
    BN: True
    activation: "" 
    kernel: 0
    stride: 0
    padding:
      type: "same"
      padding_w: 1
      padding_h: 1
  layer_14:
    set: True
    name: "layer_14"
    type: "Conv" # Normal Conv2d
    in_channels: 20
    out_channels: 20
    kernel: 3
    stride: 2
    padding:
      type: "same"
      padding_w: 1
      padding_h: 1
    BN: True
    activation: "RELU6" 
  layer_15:
    set: True
    name: "layer_15"
    type: "Add_scalar"
    kernel: 0
    stride: 0
    padding:
      type: "same"
      padding_w: 1
      padding_h: 1
    BN: False
    activation: ""
  classification:
    in_channels: 180




