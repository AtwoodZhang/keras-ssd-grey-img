{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_classes(classes_path):\n",
    "    with open(classes_path, encoding='utf-8') as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names, len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate 2007_train.txt and 2007_val.txt for train.\n",
      "Generate 2007_train.txt and 2007_val.txt for train done.\n",
      "| good | 3385 | \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------#\n",
    "#   annotation_mode用于指定该文件运行时计算的内容\n",
    "#   annotation_mode为0代表整个标签处理过程，包括获得VOCdevkit/VOC2007/ImageSets里面的txt以及训练用的2007_train.txt、2007_val.txt\n",
    "#   annotation_mode为1代表获得VOCdevkit/VOC2007/ImageSets里面的txt\n",
    "#   annotation_mode为2代表获得训练用的2007_train.txt、2007_val.txt\n",
    "#--------------------------------------------------------------------------------------------------------------------------------#\n",
    "annotation_mode     = 2\n",
    "#-------------------------------------------------------------------#\n",
    "#   必须要修改，用于生成2007_train.txt、2007_val.txt的目标信息\n",
    "#   与训练和预测所用的classes_path一致即可\n",
    "#   如果生成的2007_train.txt里面没有目标信息\n",
    "#   那么就是因为classes没有设定正确\n",
    "#   仅在annotation_mode为0和2的时候有效\n",
    "#-------------------------------------------------------------------#\n",
    "classes_path    = '/home/zhangyouan/桌面/zya/dataset/681/good_enlarge/VOCdevkit/VOC2007/voc_classes.txt'\n",
    "#--------------------------------------------------------------------------------------------------------------------------------#\n",
    "#   trainval_percent用于指定(训练集+验证集)与测试集的比例，默认情况下 (训练集+验证集):测试集 = 9:1\n",
    "#   train_percent用于指定(训练集+验证集)中训练集与验证集的比例，默认情况下 训练集:验证集 = 9:1\n",
    "#   仅在annotation_mode为0和1的时候有效\n",
    "#--------------------------------------------------------------------------------------------------------------------------------#\n",
    "trainval_percent    = 0.9\n",
    "train_percent       = 0.9\n",
    "#-------------------------------------------------------#\n",
    "#   指向VOC数据集所在的文件夹\n",
    "#   默认指向根目录下的VOC数据集\n",
    "#-------------------------------------------------------#\n",
    "VOCdevkit_path  = '/home/zhangyouan/桌面/zya/dataset/681/good_enlarge/VOCdevkit'\n",
    "\n",
    "# VOCdevkit_sets  = [('2007', 'train'), ('2007', 'val')]\n",
    "VOCdevkit_sets  = [('2007', 'trainval'), ('2007', 'test'), ('2007', 'train'), ('2007', 'val')]\n",
    "classes, _      = get_classes(classes_path)\n",
    "\n",
    "#-------------------------------------------------------#\n",
    "#   统计目标数量\n",
    "#-------------------------------------------------------#\n",
    "photo_nums  = np.zeros(len(VOCdevkit_sets))\n",
    "nums        = np.zeros(len(classes))\n",
    "def convert_annotation(year, image_id, list_file):\n",
    "    in_file = open(os.path.join(VOCdevkit_path, 'VOC%s/Annotations/%s.xml'%(year, image_id)), encoding='utf-8')\n",
    "    tree=ET.parse(in_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for obj in root.iter('object'):\n",
    "        difficult = 0 \n",
    "        if obj.find('difficult')!=None:\n",
    "            difficult = obj.find('difficult').text\n",
    "        cls = obj.find('name').text\n",
    "        if cls not in classes or int(difficult)==1:\n",
    "            continue\n",
    "        cls_id = classes.index(cls)\n",
    "        xmlbox = obj.find('bndbox')\n",
    "        b = (int(float(xmlbox.find('xmin').text)), int(float(xmlbox.find('ymin').text)), int(float(xmlbox.find('xmax').text)), int(float(xmlbox.find('ymax').text)))\n",
    "        list_file.write(\" \" + \",\".join([str(a) for a in b]) + ',' + str(cls_id))\n",
    "        \n",
    "        nums[classes.index(cls)] = nums[classes.index(cls)] + 1\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    random.seed(0)\n",
    "    if \" \" in os.path.abspath(VOCdevkit_path):\n",
    "        raise ValueError(\"数据集存放的文件夹路径与图片名称中不可以存在空格，否则会影响正常的模型训练，请注意修改。\")\n",
    "\n",
    "    if annotation_mode == 0 or annotation_mode == 1:\n",
    "        print(\"Generate txt in ImageSets.\")\n",
    "        xmlfilepath     = os.path.join(VOCdevkit_path, 'VOC2007/Annotations')\n",
    "        saveBasePath    = os.path.join(VOCdevkit_path, 'VOC2007/ImageSets/Main')\n",
    "        temp_xml        = os.listdir(xmlfilepath)\n",
    "        total_xml       = []\n",
    "        for xml in temp_xml:\n",
    "            if xml.endswith(\".xml\"):\n",
    "                total_xml.append(xml)\n",
    "\n",
    "        num     = len(total_xml)  \n",
    "        list    = range(num)  \n",
    "        tv      = int(num*trainval_percent)  \n",
    "        tr      = int(tv*train_percent)  \n",
    "        trainval= random.sample(list,tv)  \n",
    "        train   = random.sample(trainval,tr)  \n",
    "        \n",
    "        print(\"train and val size\",tv)\n",
    "        print(\"train size\",tr)\n",
    "        ftrainval   = open(os.path.join(saveBasePath,'trainval.txt'), 'w')  \n",
    "        ftest       = open(os.path.join(saveBasePath,'test.txt'), 'w')  \n",
    "        ftrain      = open(os.path.join(saveBasePath,'train.txt'), 'w')  \n",
    "        fval        = open(os.path.join(saveBasePath,'val.txt'), 'w')  \n",
    "        \n",
    "        for i in list:  \n",
    "            name=total_xml[i][:-4]+'\\n'  \n",
    "            if i in trainval:  \n",
    "                ftrainval.write(name)  \n",
    "                if i in train:  \n",
    "                    ftrain.write(name)  \n",
    "                else:  \n",
    "                    fval.write(name)  \n",
    "            else:  \n",
    "                ftest.write(name)  \n",
    "        \n",
    "        ftrainval.close()  \n",
    "        ftrain.close()  \n",
    "        fval.close()  \n",
    "        ftest.close()\n",
    "        print(\"Generate txt in ImageSets done.\")\n",
    "\n",
    "    if annotation_mode == 0 or annotation_mode == 2:\n",
    "        print(\"Generate 2007_train.txt and 2007_val.txt for train.\")\n",
    "        type_index = 0\n",
    "        for year, image_set in VOCdevkit_sets:\n",
    "            image_ids = open(os.path.join(VOCdevkit_path, 'VOC%s/ImageSets/Main/%s.txt'%(year, image_set)), encoding='utf-8').read().strip().split()\n",
    "            list_file = open('%s_%s.txt'%(year, image_set), 'w', encoding='utf-8')\n",
    "            for image_id in image_ids:\n",
    "                list_file.write('%s/VOC%s/JPEGImages/%s.jpg'%(os.path.abspath(VOCdevkit_path), year, image_id))\n",
    "\n",
    "                convert_annotation(year, image_id, list_file)\n",
    "                list_file.write('\\n')\n",
    "            photo_nums[type_index] = len(image_ids)\n",
    "            type_index += 1\n",
    "            list_file.close()\n",
    "        print(\"Generate 2007_train.txt and 2007_val.txt for train done.\")\n",
    "        \n",
    "        def printTable(List1, List2):\n",
    "            for i in range(len(List1[0])):\n",
    "                print(\"|\", end=' ')\n",
    "                for j in range(len(List1)):\n",
    "                    print(List1[j][i].rjust(int(List2[j])), end=' ')\n",
    "                    print(\"|\", end=' ')\n",
    "                print()\n",
    "\n",
    "        str_nums = [str(int(x)) for x in nums]\n",
    "        tableData = [\n",
    "            classes, str_nums\n",
    "        ]\n",
    "        colWidths = [0]*len(tableData)\n",
    "        len1 = 0\n",
    "        for i in range(len(tableData)):\n",
    "            for j in range(len(tableData[i])):\n",
    "                if len(tableData[i][j]) > colWidths[i]:\n",
    "                    colWidths[i] = len(tableData[i][j])\n",
    "        printTable(tableData, colWidths)\n",
    "\n",
    "        if photo_nums[0] <= 500:\n",
    "            print(\"训练集数量小于500，属于较小的数据量，请注意设置较大的训练世代（Epoch）以满足足够的梯度下降次数（Step）。\")\n",
    "\n",
    "        if np.sum(nums) == 0:\n",
    "            print(\"在数据集中并未获得任何目标，请注意修改classes_path对应自己的数据集，并且保证标签名字正确，否则训练将会没有任何效果！\")\n",
    "            print(\"在数据集中并未获得任何目标，请注意修改classes_path对应自己的数据集，并且保证标签名字正确，否则训练将会没有任何效果！\")\n",
    "            print(\"在数据集中并未获得任何目标，请注意修改classes_path对应自己的数据集，并且保证标签名字正确，否则训练将会没有任何效果！\")\n",
    "            print(\"（重要的事情说三遍）。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ToF': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a14582287f45bc9d1e3b7e5daac57859313a277d63546df8a468777304ae65c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
